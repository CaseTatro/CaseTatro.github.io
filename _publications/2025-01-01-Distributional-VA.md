---
title: "Should Value-Added Models Weight All Students Equally?"
collection: publications
category: works
permalink: /publication/Weighted VA Models
abstract: "Conventional value-added (VA) models estimate teacher quality as a simple average of the difference between students' actual and predicted standardized test scores. These models therefore implicitly assume it is just as important to raise test scores of lower-achieving students as it is to raise test scores of higher-achieving students. I consider whether a weighted average of residuals might be more useful. Using data from North Carolina, I find that teacher VA measures become more predictive of teachers' long-run impacts when the highest-achieving students are weighted more than the median student. Strikingly, even impacts on low-achieving students' long-run outcomes are best predicted by increasing the weight on impacts on high-achieving students' short-run outcomes. These differences in weights may reflect that either (i) small-sample efficiency (some students are more informative about teachers' true test-score effects than others) or (ii) differences in true effects (e.g. test-score effects for different students might capture different general aspects of teaching). I find empirical evidence supporting both explanations. In particular, the large weights for high-achieving students are partially but not completely explained by the fact that their residuals are less noisy."
date: 2025-12-01
venue: 'Job Market Paper'
#slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
paperurl: 'http://casetatro.github.io/files/Should_Value_Added_Models_Weight_All_Students_Equally.pdf'
#bibtexurl: 'http://academicpages.github.io/files/bibtex1.bib'
citation: "Awarded the Cliff R. Kern Excellence in Research Award (Binghamton University, Department of Economics), 2025."
---

Conventional value-added (VA) models estimate teacher quality as a simple average of the difference between students' actual and predicted standardized test scores. These models therefore implicitly assume it is just as important to raise test scores of lower-achieving students as it is to raise test scores of higher-achieving students. I consider whether a weighted average of residuals might be more useful. Using data from North Carolina, I find that teacher VA measures become more predictive of teachers' long-run impacts when the highest-achieving students are weighted more than the median student. Strikingly, even impacts on low-achieving students' long-run outcomes are best predicted by increasing the weight on impacts on high-achieving students' short-run outcomes. These differences in weights may reflect that either (i) small-sample efficiency (some students are more informative about teachers' true test-score effects than others) or (ii) differences in true effects (e.g. test-score effects for different students might capture different general aspects of teaching). I find empirical evidence supporting both explanations. In particular, the large weights for high-achieving students are partially but not completely explained by the fact that their residuals are less noisy.
